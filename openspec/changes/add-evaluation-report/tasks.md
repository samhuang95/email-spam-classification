```markdown
## 1. Implementation

- [ ] 1.1 Create `src/evaluate.py` CLI to load a model and test data and compute metrics.
- [ ] 1.2 Create `src/reporting/` to render Markdown/HTML reports and write JSON metrics.
- [ ] 1.3 Add `config/eval.yaml` for evaluation parameters (metrics, thresholds, dataset paths).
- [ ] 1.4 Add integration test `tests/integration/test_evaluate.py` using a small fixture dataset.

## 2. Docs

- [ ] 2.1 Update `README.md` with evaluation instructions.

## 3. CI

- [ ] 3.1 Add CI job to run `python -m src.evaluate --config config/eval.yaml` on sample data.
```
